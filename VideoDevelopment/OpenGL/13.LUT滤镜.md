# 13.LUT滤镜


LUT全称Look Up Table，也称为颜色查找表。       

它代表的是一种映射关系，通过LUT可以将输入的像素数组通过映射关系转换输出成另外的像素数组。     

比如一个像素的颜色值分别是R1 G1 B1，经过一次LUT操作后变为R2 G2 B2。    


LUT从查找方式上可以分为1D LUT和3D LUT:     

![Image](https://raw.githubusercontent.com/CharonChui/Pictures/master/lut_1dvs3d.webp)

- 1D LUT

对于一张RGB图像，每个通道都可以作为一个输入，用公式可以描述如下:     

![Image](https://raw.githubusercontent.com/CharonChui/Pictures/master/lut_1d.jpg)

由于颜色值的范围是（0～255），我们可以用`256*3` 的表来表示一个1D LUT，在实际操作中，我们通常以一张`256*3*1`的图片来存储这个映射表，如下，这是一张1D LUT在Mac访达中文件信息图:    
![Image](https://raw.githubusercontent.com/CharonChui/Pictures/master/lut_1d_map.jpg)

由于1D LUT各个通道都是相互独立的，无法对其他通道产生影响，因此1D LUT只能用来调节亮度/伽马/饱和度/色彩平衡等，如果我们希望对其他通道产生影响，就需要了解另一种滤镜查找方式--3D LUT。    


- 3D LUT

3D LUT在滤镜中的影响比1D LUT更为深刻，假设上图3D中的红色平面发生移动，其中对应的绿色和蓝色分量也会发生改变，也就是说，一个颜色通道改变可以影响其他的颜色通道。      

理论上3D LUT可以在立体色彩空间中描述所有颜色调整行为，所以它可以处理任何显示的非线性属性，从简单的gamma值、颜色范围和追踪错误，到修正高级的非线性属性、颜色串扰（去耦）、色相、饱和度、亮度等，3D LUT都可以胜任。


常见的3D LUT滤镜文件与.cube或者.3dl都是把3D坐标二维化后的数据表现，如下图

![Image](https://raw.githubusercontent.com/CharonChui/Pictures/master/3d_lut.jpg)


我们看到的这些方格子里面的蓝色是固定的，然后每个格子横坐标是红色，纵坐标是绿色，最左上角的格子因为蓝色全无，所以红色和绿色就很明显，而最右下角的那个格子，蓝色色值达到最大，因此整体看上去就非常的蓝(从左上角的格子到右下角的格子，一共是8行8列，正好是64个格子)。


### 为什么是64x64

对于RGB颜色，每种颜色可以有256种取值，因此一个3D LUT 如果全量表示的话，大小为`256*256*256`，如果我们有一个大小为`256*256*256`的3D LUT文件，那么颜色映射将非常简单，只要根据RGB的像素值按照用蓝色找到对应的格子，然后用红色和绿色找到对应格子的横列就可以找到映射的颜色值。但是通常情况下，我们不会这么干，因为一张`256*256*256`的图实在是太大了，至少需要48MB的存储空间。

如果要完全记录这种映射关系，设备需要耗费大量的内存，并且可能在计算时因为计算量大而产生性能问题， 为了简化计算量，降低内存占用，可以将相近的n种颜色采用一条映射记录并存储，(n通常为4)这样只需要64X64X64种就可以表示原来256X256X256的颜色数量，我们也将4称为采样步长。

在专业领域一般认为17x17x17的3D LUT足够适用于预览和监看；65x65x65或者更大的3D LUT更适合渲染和调色。     


### 3D LUT映射

要想熟练使用LUT滤镜，我们首先要了解它是怎么建立颜色映射关系的， 我们看下以下这张图，这张图展示了在LUT中RBG颜色是如何实现映射关系的:       
![Image](https://raw.githubusercontent.com/CharonChui/Pictures/master/lut.png)

首先这张图的大小是512X512，在横竖方向上这张图都被分成了8个小方格(64只是一种颜色粒度的划分，可以是其它数值，具体的看设计师给出查找表是怎么规划的，此处的粒度为64，也就是将RGB的分量划分为64份，颜色[0.0, 1.0] -> [0.0, 63.0]):      

- 每个小方格的大小是64X64，也就是一张512X512的图被分割成64个小方格
- 每个小方格的大小是64X64，这64个小方格就代表了64种B通道的颜色映射
- 然后每个B通道的小方格上又是一个64X64像素大小的图像，这个小图像的横坐标代表R分量的64种映射情况，纵坐标代表了G分量的64种映射情况

这样就刚好这就和采样步长是4的映射表对应上了。

**在使用上面这张LUT表的时候首选需要找对B分量对应的小格子，然后在找到的小个子上再计算出R分量和G分量的映射结果即可得到完整的RGB映射结果。**



下面我们就以一个`64*64*64`的3D LUT为例，来说明一下3D LUT如何查找和使用的（用glsl来实现）:     

- 整张图从左到右和从上到下为蓝色的渐变，每个小格子从左到右为红色渐变，从上到下为绿色渐变
- 肉眼可见的有8*8个方格，假设整个图的范围我们定义为0.0~1.0 ，也就是说每个格子所表示的范围是1./8. = 0.125
- 我们首先通过蓝色来查找我们在哪个方格，由于涉及到插值，因此通过蓝色进行查找的时候，可能不会那么幸运一定映射到整数的格子上面，因此我们需要通过向下取整和向上进位两种方式来获取蓝色所对应的方格，然后通过蓝色的颜色值来mix这两种的颜色值，从而获取最终的颜色值。   


### 映射示例

以一个具体的颜色Color(r=30.0, g=30.0, b=25.4)为例子来说明是如何通过LUT来做映射的。

#### 1.1 寻找B值的两个格子

B值对应的是0 ~ 63，共64个格子，在计算时，并不一定会是一个整数，对应到某一个格子，大概率会是一个小数，为了能够更精确的进行映射，需要使用两个格子，然后根据小数(因子)进行插值计算，从而能够更精确。    

##### 蓝色值用来定位两个相邻的小格子

- 第一个小格子:         

```python
float blueColor = textureColor.b * 63.0;
vec2 quad1;
// blueColor = 25.4, 第3行的第1个小格子
// floor:向下取整
quad1.y = floor(floor(blueColor) / 8.0);
quad1.x = floor(blueColor) - (quad1.y * 8.0);
```

- 第二个小格子:     

```python
vec2 quad2;
// blueColor = 25.4，第3行的第2个小格子
// ceil：向上取整
quad2.y = floor(ceil(blueColor) / 8.0);
quad2.x = ceil(blueColor) - (quad2.y * 8.0);
```

##### 确定每个格子对应的R G值

红色值和绿色值用来确定相对于整个LUT的纹理坐标:   

```python
vec2 texPos1;
texPos1.x = (quad1.x * 1.0 / 8.0) + (63.0 / 512.0) * textureColor.r);
texPos1.y = (quad1.y * 1.0 / 8.0) + (63.0 / 512.0) * textureColor.g);

vec2 texPos2;
texPos2.x = (quad2.x * 1.0 / 8.0) + (63.0 / 512.0) * textureColor.r);
texPos2.y = (quad2.y * 1.0 / 8.0) + (63.0 / 512.0) * textureColor.g);
```

##### 通过纹理坐标获取两个新的颜色   

```python
vec4 newColor1 = texture2D(u_LookupTable, texPos1);
vec4 newColor2 = texture2D(u_LookupTable, texPos2);
```

##### 然后根据蓝色值小数部分作为权重做线性混合，获取最终的颜色输出


```python
// mix(x, y, a) -> x * (1 - a) + y * a
vec4 newColor = mix(newColor1, newColor2, fract(blueColor));
```

完整的顶点着色器:   

```python
attribute vec4 a_Position;
attribute vec4 a_TextureCoordinate;

varying vec2 vTextureUnitCoordinate;

void main() {
    gl_Position = a_Position;
    vTextureUnitCoordinate = a_TextureCoordinate.xy;
}
```

片元着色器代码:     

```python
precision mediump float;

uniform sampler2D u_TextureSampler;
uniform sampler2D u_LookupTable;
uniform float u_Intensity;

varying vec2 vTextureUnitCoordinate;

void main() {
    vec4 textureColor = texture2D(u_TextureSampler, vTextureUnitCoordinate);
    float blueColor = textureColor.b * 63.0;
    vec2 quad1;
    quad1.y = floor(floor(blueColor) / 8.0);
    quad1.x = floor(blueColor) - (quad1.y * 8.0);

    vec2 quad2;
    quad2.y = floor(ceil(blueColor) / 8.0);
    quad2.x = ceil(blueColor) - (quad2.y * 8.0);

    vec2 texPos1;
    texPos1.x = (quad1.x * 0.125) + 0.5/512.0 + ((0.125 - 1.0/512.0) * textureColor.r);
    texPos1.y = (quad1.y * 0.125) + 0.5/512.0 + ((0.125 - 1.0/512.0) * textureColor.g);

    vec2 texPos2;
    texPos2.x = (quad2.x * 0.125) + 0.5/512.0 + ((0.125 - 1.0/512.0) * textureColor.r);
    texPos2.y = (quad2.y * 0.125) + 0.5/512.0 + ((0.125 - 1.0/512.0) * textureColor.g);

    vec4 newColor1 = texture2D(u_LookupTable, texPos1);
    vec4 newColor2 = texture2D(u_LookupTable, texPos2);

    vec4 newColor = mix(newColor1, newColor2, fract(blueColor));
    gl_FragColor = mix(textureColor, vec4(newColor.rgb, textureColor.w), u_Intensity);
}
```




[上一篇: 12.FBO](https://github.com/CharonChui/AndroidNote/blob/master/VideoDevelopment/OpenGL/12.FBO.md)
[下一篇: 14.实例化](https://github.com/CharonChui/AndroidNote/blob/master/VideoDevelopment/OpenGL/14.%E5%AE%9E%E4%BE%8B%E5%8C%96.md)


---

- 邮箱 ：charon.chui@gmail.com  
- Good Luck! 































