RAG
---


### RAG概念


RAG(Retrieval Augmented Generation)：检索增强生成。     

顾名思义，就是通过检索外部数据，增强大模型的生成效果。   

RAG为LLM提供了从某些数据源检索到的信息，并基于此修正生成的答案。      

RAG基本上是Search + LLM提示，可以通过大模型回答查询，并将搜索算法所找到的信息作为大模型的上下文。查询和检索到的上下文都会被注入发送到LLM的提示语中。    




将大模型应用于实际业务场景时会发现，通用的基础大模型基本无法满足我们的实际业务需求，主要有以下几个方面的原因:      

- LLM的知识不是实时的，不具备知识更新
- LLM可能不知道你私有的领域/业务知识
- LLM有时会在回答中生成看似合理但实际上是错误的信息  


为什么会用RAG

- 提高准确性: 通过检索相关的信息，RAG可以提高生成文本的准确性
- 减少训练成本: 与需要大量数据来训练的大型生成模型相比，RAG可以通过检索机制来减少所需的训练数据量，从而降低训练成本。
- 适应性强: RAG模型可以适应新的或不断变化的数据，由于它们能够检索最新的消息，因此在新数据和事件出现时，它们能够快速适应并生成相关的文本。   


RAG系统兼具检索与生成的双重能力，可视为传统生成系统的升级版：既有效减少了幻觉现象，又显著提升了回答的事实准确性。该技术还支持“与数据对话”(chat with my data)的应用场景，使企业和个人能够将LLM与内部数据或特定数据源（如书籍内容）对接。

RAG技术是一种结合信息检索与生成模型的新型架构，其核心思想是利用外部知识库或文档集合为大模型提供实时、准确的背景信息，从而弥补大模型的局限性。   


![Image](https://raw.githubusercontent.com/CharonChui/Pictures/master/rag.png?raw=true)        





































