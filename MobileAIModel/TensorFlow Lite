TensorFlow Lite
---

[TensorFlow Lite](https://tensorflow.google.cn/lite?hl=zh-cn) 是一个移动端库，可用于在移动设备、微控制器和其他边缘设备上部署模型。


[TensorFlow Lite](https://tensorflow.google.cn/lite?hl=zh-cn) 是一组工具，可帮助开发者在移动设备、嵌入式设备和 loT 设备上运行模型，以便实现设备端机器学习。


TensorFlow Lite是TensorFlow在手机和嵌入设备上的一个轻量级框架。      

主要特性:  

- 通过解决以下 5 项约束条件，针对设备端机器学习进行了优化：延时（数据无需往返服务器）、隐私（没有任何个人数据离开设备）、连接性（无需连接互联网）、大小（缩减了模型和二进制文件的大小）和功耗（高效推断，且无需网络连接）。
- 支持多种平台，涵盖 Android 和 iOS 设备、嵌入式 Linux 和微控制器。
- 支持多种语言，包括 Java、Swift、Objective-C、C++ 和 Python。
高性能，支持硬件加速和模型优化。
- 提供多种平台上的常见机器学习任务的端到端示例，例如图像分类、对象检测、姿势估计、问题回答、文本分类等。


1. 创建 TensorFlow Lite 模型
TensorFlow Lite 模型以名为 FlatBuffer 的专用高效可移植格式（由“.tflite”文件扩展名标识）表示。      

与 TensorFlow 的协议缓冲区模型格式相比，这种格式具有多种优势，例如可缩减大小（代码占用的空间较小）以及提高推断速度（可直接访问数据，无需执行额外的解析/解压缩步骤），这样一来，TensorFlow Lite 即可在计算和内存资源有限的设备上高效地运行。

TensorFlow Lite 模型可以选择包含元数据，并在元数据中添加人类可读的模型说明和机器可读的数据，以便在设备推断过程中自动生成处理前和处理后流水线。如需了解详情，请参阅添加元数据。

您可以通过以下方式生成 TensorFlow Lite 模型：

使用现有的 TensorFlow Lite 模型：若要选择现有模型，请参阅 TensorFlow Lite 示例。模型可能包含元数据，也可能不含元数据。

创建 TensorFlow Lite 模型：使用 TensorFlow Lite Model Maker，利用您自己的自定义数据集创建模型。默认情况下，所有模型都包含元数据。

将 TensorFlow 模型转换为 TensorFlow Lite 模型：使用 TensorFlow Lite Converter 将 TensorFlow 模型转换为 TensorFlow Lite 模型。在转换过程中，您可以应用量化等优化措施，以缩减模型大小和缩短延时，并最大限度降低或完全避免准确率损失。默认情况下，所有模型都不含元数据。




