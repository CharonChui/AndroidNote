# volatile和Synchronized

## 内存模型

内存模型：英文名 Memory Model，它是一个老古董了。它是与计算机硬件有关的一个概念。那么，我先介绍下它和硬件到底有啥关系。

计算机在执行程序的时候，每条指令都是在CPU中执行的，而执行的时候，又免不了要和数据打交道。而计算机上面的数据，是存放在主存当中的，也就是计算机的物理内存。但是随着CPU技术的发展，CPU的执行速度越来越快。而由于内存的技术并没有太大的变化，所以从内存中读取和写入数据的过程和CPU的执行速度比起来差距就会越来越大,这就导致CPU每次操作内存都要耗费很多等待时间。可是，不能因为内存的读写速度慢，就不发展CPU技术了，所以人们想出来了一个好的办法，就是在CPU和内存之间增加高速缓存。缓存的概念大家都知道，就是保存一份数据拷贝。他的特点是速度快，内存小，并且昂贵。

那么，程序的执行过程就变成了：当程序在运行过程中，会将运算需要的数据从主存复制一份到CPU的高速缓存当中，那么CPU进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高速缓存中的数据刷新到主存当中。而随着CPU能力的不断提升，一层缓存就慢慢的无法满足要求了，就逐渐的衍生出多级缓存。按照数据读取顺序和与CPU结合的紧密程度，CPU缓存可以分为一级缓存（L1），二级缓存（L3），部分高端CPU还具有三级缓存（L3），每一级缓存中所储存的全部数据都是下一级缓存的一部分。

这三种缓存的技术难度和制造成本是相对递减的，所以其容量也是相对递增的。

那么，在有了多级缓存之后，程序的执行就变成了：

当CPU要读取一个数据时，首先从一级缓存中查找，如果没有找到再从二级缓存中查找，如果还是没有就从三级缓存或内存中查找。

> 这就像一家创业公司，刚开始，创始人和员工之间工作关系其乐融融，但是随着创始人的能力和野心越来越大，逐渐和员工之间出现了差距，普通员工原来越跟不上CEO的脚步。老板的每一个命令，传到到基层员工之后，由于基层员工的理解能力、执行能力的欠缺，就会耗费很多时间。这也就无形中拖慢了整家公司的工作效率。
>
> 之后，这家公司开始设立中层管理人员，管理人员直接归CEO领导，领导有什么指示，直接告诉管理人员，然后就可以去做自己的事情了。管理人员负责去协调底层员工的工作。因为管理人员是了解手下的人员以及自己负责的事情的。所以，大多数时候，公司的各种决策，通知等，CEO只要和管理人员之间沟通就够了。
>
> 随着公司越来越大，老板要管的事情越来越多，公司的管理部门开始改革，开始出现高层，中层，底层等管理者。一级一级之间逐层管理。
>
> 公司也分很多种，有些公司只有一个大Boss，他一个人说了算。但是有些公司有比如联席总经理、合伙人等机制。
>
> 单核CPU就像一家公司只有一个老板，所有命令都来自于他，那么就只需要一套管理班底就够了。
>
> 多核CPU就像一家公司是由多个合伙人共同创办的，那么，就需要给每个合伙人都设立一套供自己直接领导的高层管理人员，多个合伙人共享使用的是公司的底层员工。
>
> 还有的公司，不断壮大，开始拆分出各个子公司。各个子公司就是多个CPU了，互相使用没有共用的资源。互不影响。

随着计算机能力不断提升，开始支持多线程。那么问题就来了。我们分别来分析下单线程、多线程在单核CPU、多核CPU中的影响。

**单线程**：cpu核心的缓存只被一个线程访问。缓存独占，不会出现访问冲突等问题。

**单核CPU，多线程**：进程中的多个线程会同时访问进程中的共享数据，CPU将某块内存加载到缓存后，不同线程在访问相同的物理地址的时候，都会映射到相同的缓存位置，这样即使发生线程的切换，缓存仍然不会失效。但由于任何时刻只能有一个线程在执行，因此不会出现缓存访问冲突。

**多核CPU，多线程**：每个核都至少有一个L1缓存。多个线程访问进程中的某个共享内存，且这多个线程分别在不同的核心上执行，则每个核心都会在各自的cache中保留一份共享内存的缓存。由于多核是可以并行的，可能会出现多个线程同时写各自的缓存的情况，而各自的cache之间的数据就有可能不同。

在CPU和主存之间增加缓存，在多线程场景下就可能存在**缓存一致性问题**，也就是说，在多核CPU中，每个核的自己的缓存中，关于同一个数据的缓存内容可能不一致。

> 如果这家公司的命令都是串行下发的话，那么就没有任何问题。
>
> 如果这家公司的命令都是并行下发的话，并且这些命令都是由同一个CEO下发的，这种机制是也没有什么问题。因为他的命令执行者只有一套管理体系。
>
> 如果这家公司的命令都是并行下发的话，并且这些命令是由多个合伙人下发的，这就有问题了。因为每个合伙人只会把命令下达给自己直属的管理人员，而多个管理人员管理的底层员工可能是公用的。
>
> 比如，合伙人1要辞退员工a，合伙人2要给员工a升职，升职后的话他再被辞退需要多个合伙人开会决议。两个合伙人分别把命令下发给了自己的管理人员。合伙人1命令下达后，管理人员a在辞退了员工后，他就知道这个员工被开除了。而合伙人2的管理人员2这时候在没得到消息之前，还认为员工a是在职的，他就欣然的接收了合伙人给他的升职a的命令。

### 处理器优化和指令重排

上面提到在CPU和主存之间增加缓存，在多线程场景下会存在**缓存一致性问题**。除了这种情况，还有一种硬件问题也比较重要。那就是为了使处理器内部的运算单元能够尽量的被充分利用，处理器可能会对输入代码进行乱序执行处理。这就是**处理器优化**。

除了现在很多流行的处理器会对代码进行优化乱序处理，很多编程语言的编译器也会有类似的优化，比如Java虚拟机的即时编译器（JIT）也会做**指令重排**。

可想而知，如果任由处理器优化和编译器对指令重排的话，就可能导致各种各样的问题。

> 关于员工组织调整的情况，如果允许人事部在接到多个命令后进行随意拆分乱序执行或者重排的话，那么对于这个员工以及这家公司的影响是非常大的。

### 并发编程问题

并发编程，为了保证数据的安全，需要满足以下三个特性：

**原子性**是指在一个操作中就是cpu不可以在中途暂停然后再调度，既不被中断操作，要不执行完成，要不就不执行。

**可见性**是指当多个线程访问同一个变量时，一个线程修改了这个变量的值，其他线程能够立即看得到修改的值。

**有序性**即程序执行的顺序按照代码的先后顺序执行。

有没有发现，**缓存一致性问题**其实就是**可见性问题**。而**处理器优化**是可以导致**原子性问题**的。**指令重排**即会导致**有序性问题**。所以，后文将不再提起硬件层面的那些概念，而是直接使用大家熟悉的原子性、可见性和有序性。

前面提到的，缓存一致性问题、处理器器优化的指令重排问题是硬件的不断升级导致的。那么，有没有什么机制可以很好的解决上面的这些问题呢？

最简单直接的做法就是废除处理器和处理器的优化技术、废除CPU缓存，让CPU直接和主存交互。但是，这么做虽然可以保证多线程下的并发问题。但是，这就有点因噎废食了。

所以，为了保证并发编程中可以满足原子性、可见性及有序性。有一个重要的概念，那就是——内存模型。

**为了保证共享内存的正确性（可见性、有序性、原子性），内存模型定义了共享内存系统中多线程程序读写操作行为的规范**。通过这些规则来规范对内存的读写操作，从而保证指令执行的正确性。它与处理器有关、与缓存有关、与并发有关、与编译器也有关。他解决了CPU多级缓存、处理器优化、指令重排等导致的内存访问问题，保证了并发场景下的一致性、原子性和有序性。

内存模型解决并发问题主要采用两种方式：**限制处理器优化**和**使用内存屏障**。

## Java内存模型

**Java内存模型**(java Memory Model，JMM)描述了Java程序中各种变量(**线程共享变量**)的访问规则，以及在JVM中将变量**存储到内存**和从**内存中读取出变量**这样的底层细节。

Java内存模型规定了所有的变量都存储在主内存中，每条线程还有自己的工作内存，线程的工作内存中保存了该线程中是用到的变量的主内存副本拷贝，线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存(每个线程都分配有单独的处理器缓存，用这些处理器缓存去缓存一些数据，就可以不用再次访问主内存去获取相应的数据，这样就可以提高效率)。不同的线程之间也无法直接访问对方工作内存中的变量，线程间变量的传递均需要自己的工作内存和主存之间进行数据同步进行。而JMM就作用于工作内存和主存之间数据同步过程。他规定了如何做数据同步以及什么时候做数据同步。对于共享普通变量来说，约定了变量在工作内存中发生变化了之后，必须要回写到工作内存(**迟早要回写但并非马上回写**)，*但对于volatile变量则要求工作内存中发生变化之后，必须马上回写到工作内存，而线程读取volatile变量的时候，必须马上到工作内存中去取最新值而不是读取本地工作内存的副本*，此规则保证了前面所说的“当线程A对变量X进行了修改后，在线程A后面执行的其他线程能看到变量X的变动”。

![](https://raw.githubusercontent.com/CharonChui/Pictures/master/java_mm.png)

这里面提到的主内存和工作内存，读者可以简单的类比成计算机内存模型中的主存和缓存的概念。特别需要注意的是，主内存和工作内存与JVM内存结构中的Java堆、栈、方法区等并不是同一个层次的内存划分，无法直接类比。《深入理解Java虚拟机》中认为，如果一定要勉强对应起来的话，从变量、主内存、工作内存的定义来看，主内存主要对应于Java堆中的对象实例数据部分。工作内存则对应于虚拟机栈中的部分区域。

**所以，再来总结下，JMM是一种规范，目的是解决由于多线程通过共享内存进行通信时，存在的本地内存数据不一致、编译器会对代码指令重排序、处理器会对代码乱序执行等带来的问题。**

## volatile

作用：使变量在多个线程间可见（可见性），能够保证volatile变量的可见性，但不能保证volatile变量复合操作的原子性。

`Java`语言规范中指出：为了获得最佳速度，允许线程保存共享成员变量的私有拷贝，而在这个过程中,变量的新值对其他线程是不可见的.而且只当线程进入或者离开同步代码块时才与共享成员变量
的原始值对比。这样当多个线程同时与某个对象交互时，就必须要注意到要让线程及时的得到共享成员变量的变化。也就是说每个线程都有一个自己的本地内存空间，在线程执行时，先把变量从主内存读取到线程自己的本地内存空间，然后再对该变量进行操作，当对该变量操作完后，在某个时间再把变量刷新回主内存。

- volatile如何实现内存可见性。深入来说：通过加入**内存屏障**和**禁止重排序优化**来实现的
- 对volatile变量执行写操作时，会在写操作后加入一条store屏障指令
- 对volatile变量执行读操作时，会在读操作前加入一条load屏障指令

当volatile修饰一个变量i在线程1中从1发生改变成2时，这时线程1会做两件事：

1. **更新主内存。**
2. **向CPU总线发送一个修改信号。**

**这时监听CPU总线的处理器会收到这个修改信号后，如果发现修改的数据自己缓存了，就把自己缓存的数据失效掉。这样其它线程访问到这段缓存时知道缓存数据失效了，需要从主内存中获取。这样所有线程中的共享变量i就达到了一致性。**

![img](https://raw.githubusercontent.com/CharonChui/Pictures/master/java_mm_1.jpg)

**所以volatile也可以看作线程间通信的一种廉价方式。**

### volatile关键字的非原子性

所谓原子性，就是某系列的操作步骤要么全部执行，要么都不执行。

比如，变量的自增操作 i++，分三个步骤：

- 从内存中读取出变量 i 的值
- 将i的值加1
- 将加1后的值写回内存

这说明 i++ 并不是一个原子操作。因为，它分成了三步，有可能当某个线程执行到了第②时被中断了，那么就意味着只执行了其中的两个步骤，没有全部执行。

volatile修饰的变量并不保证对它的操作（自增）具有原子性。（对于自增操作，可以使用JAVA的原子类AutoicInteger类保证原子自增）

比如，假设i自增到5，线程A从主内存中读取i，值为5，将它存储到自己的线程空间中，执行加1操作，值为6。此时，CPU切换到线程B执行，从主从内存中读取变量i的值。由于线程A还没有来得及将加1后的结果写回到主内存，线程B就已经从主内存中读取了i，因此，线程B读到的变量i值还是5。

相当于线程B读取的是已经过时的数据了，从而导致线程不安全性。这种情形在《Effective JAVA》中称之为“安全性失败”

**综上，仅靠volatile不能保证线程的安全性。（原子性）**

### volatile禁止指令重排序

代码书写的顺序与实际执行的顺序不同，指令重排序是编译器或处理器为了提高程序性能而做的优化

1. **编译器优化的重排序（编译器优化）**
2. **指令级并行重排序（处理器优化）**
3. **内存系统的重排序（处理器优化）**

volatile禁止指令重排序，典型的应用是单例模式中的双重检查机制。

由于synchronized是一个重量级锁，会影响运行效率。双重检查机制中，先判断单例变量是否为null，再进入同步代码块。这样只在第一次获取单例变量时，会有效率影响。

```java
public class DoubleCheckSingleton {

	private volatile static DoubleCheckSingleton singleton;

	private DoubleCheckSingleton() {}

	public static DoubleCheckSingleton getInstance() {
		if(singleton == null) {
			synchronized (singleton) {
				if(singleton == null) {
					singleton = new DoubleCheckSingleton();
				}
			}
		}
		return singleton;
	}

}
```

单例变量需要用volatile修饰，否则，在new单例对象时会出现问题。使用new来创建一个对象可以分解为如下的3行伪代码：

```java
memory = allocate();   //1.分配对象的内存空间
ctorInstance(memory);  //2.初始化对象
instance = memory;     //3.设置instance指向刚分配的内存地址
```

上面3行伪代码中的2和3之间可能会发生重排序，排序后的执行顺序如下：

```java
memory = allocate();   //1.分配对象的内存空间
instance = memory;     //3.设置instance指向刚分配的内存地址，此时对象还没有初始化，但instance == null 判断为false
ctorInstance(memory);  //2.初始化对象
```

指令重排序后，在多线程情况下，可能会发生A线程正在new对象，执行了3，但还没有执行2。此时B线程进入方法获取单例对象，执行同步代码块外的非空判断，发现变量非空，但此时对象还未初始化，B线程获取到的是一个未被初始化的对象。使用volatile修饰后，禁止指令重排序。即，先初始化对象后，再设置instance指向刚分配的内存地址。这样就就不存在获取到未被初始化的对象。



那为何说它禁止指令重排序呢？从硬件架构上讲，指令重排序是指处理器采用了允许将多条指令不按程序规定的顺序分开发送给各个相应的电路单元进行处理。但并不是说指令任意重排，处理器必须能正确处理指令依赖情况保障程序能得出正确的执行结果。譬如指令1把地址A中的值加10，指令2把地址A中的值乘以2，指令3把地址B中的值减去3，这时指令1和指令2是有依赖的，它们之间的顺序不能重排——(A+10)*2与A*2+10显然不相等，但指令3可以重排到指令1、2之前或者中间，只要保证处理器执行后面依赖到A、B值的操作时能获取正确的A和B值即可。所以在同一个处理器中，重排序过的代码看起来依然是有序的。因此，lock addl$0x0，(%esp)指令把修改同步到内存时，意味着所有之前的操作都已经执行完成，这样便形成了“指令重排序无法越过内存屏障”的效果。



## synchronized

**synchronized实现同步的基础是：Java中的每个对象都可作为锁。所以synchronized锁的都对象，只不过不同形式下锁的对象不一样。**

- **对于普通同步方法，锁的是当前实例对象。**
- **对于静态同步方法，锁的是当前类的Class对象。**
- **对于同步方法块，锁是Synchronized括号里配置的对象。**

`synchronized`为一段操作或内存进行加锁，它具有互斥性。当线程要操作被`synchronized`修饰的内存或操作时，必须首先获得锁才能进行后续操作；但是在同一时刻只能有一个线程获得相同的一把锁（对象监视器），所以它只允许一个线程进行操作。
它用来修饰一个方法或者一个代码块的时候，能够保证在同一时刻最多只有一个线程执行该段代码。

- 当两个并发线程访问同一个对象中的这个`synchronized(this)`同步代码块时，一个时间内只能有一个线程得到执行。另一个线程必须等待当前线程执行完这个代码块以后才能执行该代码块。
- 然而，当一个线程访问`object`的一个`synchronized(this)`同步代码块时，另一个线程仍然可以访问该`object`中的非`synchronized(this)`同步代码块。
- 尤其关键的是，当一个线程访问`object`的一个`synchronized(this)`同步代码块时，其他线程对`object`中所有其它`synchronized(this)`同步代码块的访问将被阻塞。

**在JVM规范中规定了synchronized是通过Monitor对象来实现方法和代码块的同步，但两者实现细节有点一不样。代码块同步是使用monitorenter和monitorexit指令，方法同步是使用另外一种方法实现，细节JVM规范并没有详细说明。但是，方法的同步同样可以使用这两指令来实现。**

**monitorenter指令是编译后插入到同步代码块的开始位置，而monitorexit指令是插入到方法结束处和异常处。JVM保证了每个monitorenter都有对应的monitorexit。任何一个对象都有一个monitor与之关联，当且一个monitor被持有后，对象将处于锁定状态。线程执行到monitorenter指令时，将会尝试获取对象对应monitor的所有权，即尝试获得对象的锁。**

### synchronized缺点

#### 有性能损耗

虽然在JDK 1.6中对synchronized做了很多优化，如如适应性自旋、锁消除、锁粗化、轻量级锁和偏向锁等，但是他毕竟还是一种锁。以上这几种优化，都是尽量想办法避免对Monitor进行加锁，但是，并不是所有情况都可以优化的，况且就算是经过优化，优化的过程也是有一定的耗时的。所以，无论是使用同步方法还是同步代码块，在同步操作之前还是要进行加锁，同步操作之后需要进行解锁，这个加锁、解锁的过程是要有性能损耗的。

Monitor其实是一种同步工具，也可以说是一种同步机制，它通常被描述为一个对象，主要特点是：

> 对象的所有方法都被“互斥”的执行。好比一个Monitor只有一个运行“许可”，任一个线程进入任何一个方法都需要获得这个“许可”，离开时把许可归还。
>
> 通常提供singal机制：允许正持有“许可”的线程暂时放弃“许可”，等待某个谓词成真（条件变量），而条件成立后，当前进程可以“通知”正在等待这个条件变量的线程，让他可以重新去获得运行许可。

#### 产生阻塞

基于Monitor对象，当多个线程同时访问一段同步代码时，首先会进入Entry Set，当有一个线程获取到对象的锁之后，才能进行The  Owner区域，其他线程还会继续在Entry Set等待。并且当某个线程调用了wait方法后，会释放锁并进入Wait Set等待。

![img](http://47.103.216.138/wp-content/uploads/2019/08/15660298698995.jpg)￼

所以，synchronize实现的锁本质上是一种阻塞锁，也就是说多个线程要排队访问同一个共享对象。

## volatile与Synchronized的区别：

- synchronized通过加锁的方式，使得其在需要原子性、可见性和有序性这三种特性的时候都可以作为其中一种解决方案，看起来是“万能”的。的确，大部分并发控制操作都能使用synchronized来完成。
- volatile通过在volatile变量的操作前后插入内存屏障的方式，保证了变量在并发场景下的可见性和有序性。
- volatile关键字是无法保证原子性的，而synchronized通过monitorenter和monitorexit两个指令，可以保证被synchronized修饰的代码在同一时间只能被一个线程访问，即可保证不会出现CPU时间片在多个线程间切换，即可保证原子性
- volatile是变量修饰符，而synchronized则作用于一段代码或方法。
- volatile只是在线程内存和“主”内存间同步某个变量的值；而synchronized通过锁定和解锁某个监视器同步所有变量的值。显然synchronized要比volatile消耗更多资源。

一句话，那什么时候才能用volatile关键字呢？（千万记住了，重要事情说三遍，感觉这句话过时了）

> 如果写入变量值不依赖变量当前值，那么就可以用 volatile
>
> 如果写入变量值不依赖变量当前值，那么就可以用 volatile
>
> 如果写入变量值不依赖变量当前值，那么就可以用 volatile

比如上面 count++ ，是获取-计算-写入三步操作，也就是依赖当前值的，所以不能靠volatile 解决问题。

参考:

- [再有人问你Java内存模型是什么，就把这篇文章发给他](https://www.hollischuang.com/archives/2550)
- [原子性、可见性以及有序性](https://github.com/CharonChui/AndroidNote/blob/master/JavaKnowledge/%E5%8E%9F%E5%AD%90%E6%80%A7%E3%80%81%E5%8F%AF%E8%A7%81%E6%80%A7%E4%BB%A5%E5%8F%8A%E6%9C%89%E5%BA%8F%E6%80%A7.md)

---

- 邮箱 ：charon.chui@gmail.com
- Good Luck!
